{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2884c06a-517e-4421-af93-13727038669f",
   "metadata": {},
   "source": [
    "**<h1>1. Loading and Preprocessing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06fbdbc2-fc3b-458d-afc2-891406035a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import the necessary libraries:\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ab5d89-42b6-42f7-b45e-70f0cfc78185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  Target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to load the dataset:\n",
    "california_data = fetch_california_housing()\n",
    "\n",
    "# to convert to a DataFrame:\n",
    "data = pd.DataFrame(california_data.data, columns=california_data.feature_names)\n",
    "data['Target'] = california_data.target  # Add target column\n",
    "\n",
    "# to display the first few rows of the dataset:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c6bf4c-01d1-4178-ab31-a86b622621c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "Target        0\n",
      "dtype: int64\n",
      "Missing values after handling:\n",
      "MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "Target        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# to check missing values:\n",
    "print(\"Missing values before handling:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# to handle missing values (if any):\n",
    "# In this dataset, there are no missing values, but if there were:\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "print(\"Missing values after handling:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9174ad94-32cd-409a-be7b-1d42a77bb0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.344766</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.628559</td>\n",
       "      <td>-0.153758</td>\n",
       "      <td>-0.974429</td>\n",
       "      <td>-0.049597</td>\n",
       "      <td>1.052548</td>\n",
       "      <td>-1.327835</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.332238</td>\n",
       "      <td>-0.607019</td>\n",
       "      <td>0.327041</td>\n",
       "      <td>-0.263336</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>-0.092512</td>\n",
       "      <td>1.043185</td>\n",
       "      <td>-1.322844</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.782699</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>1.155620</td>\n",
       "      <td>-0.049016</td>\n",
       "      <td>-0.820777</td>\n",
       "      <td>-0.025843</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.332827</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.932968</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.156966</td>\n",
       "      <td>-0.049833</td>\n",
       "      <td>-0.766028</td>\n",
       "      <td>-0.050329</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.337818</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012881</td>\n",
       "      <td>1.856182</td>\n",
       "      <td>0.344711</td>\n",
       "      <td>-0.032906</td>\n",
       "      <td>-0.759847</td>\n",
       "      <td>-0.085616</td>\n",
       "      <td>1.038503</td>\n",
       "      <td>-1.337818</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  2.344766  0.982143  0.628559  -0.153758   -0.974429 -0.049597  1.052548   \n",
       "1  2.332238 -0.607019  0.327041  -0.263336    0.861439 -0.092512  1.043185   \n",
       "2  1.782699  1.856182  1.155620  -0.049016   -0.820777 -0.025843  1.038503   \n",
       "3  0.932968  1.856182  0.156966  -0.049833   -0.766028 -0.050329  1.038503   \n",
       "4 -0.012881  1.856182  0.344711  -0.032906   -0.759847 -0.085616  1.038503   \n",
       "\n",
       "   Longitude  Target  \n",
       "0  -1.327835   4.526  \n",
       "1  -1.322844   3.585  \n",
       "2  -1.332827   3.521  \n",
       "3  -1.337818   3.413  \n",
       "4  -1.337818   3.422  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to initialize the scaler:\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# to scale the features (excluding the target):\n",
    "scaled_features = scaler.fit_transform(data.iloc[:, :-1])\n",
    "\n",
    "# to convert scaled features back to a DataFrame:\n",
    "scaled_data = pd.DataFrame(scaled_features, columns=california_data.feature_names)\n",
    "scaled_data['Target'] = data['Target']\n",
    "\n",
    "# to display the first few rows of the scaled dataset:\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601443db-fa2e-4b34-bf5e-94e1b2f5fc59",
   "metadata": {},
   "source": [
    "**Handling Missing Values:**\r\n",
    "\r\n",
    "Checked for missing values in the dataset. Since missing values can cause issues during training, replaced them with the mean of the respective columns. This ensures no data loss while maintaining statistical integritworks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae00d29-d450-4590-b344-0b92bc71cd27",
   "metadata": {},
   "source": [
    "**Feature Scaling:**\n",
    "\n",
    "Applied standardization using StandardScaler to ensure all features have a mean of 0 and a standard deviation of 1. This step is crucial because features with varying scales can negatively impact models like logistic regression and neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ef8ff0-93fe-4672-a1e3-3225d0ffddde",
   "metadata": {},
   "source": [
    "**<h1>2. Regression Algorithm Implementation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8a6bf1d-0994-4ca2-ac61-8ab5d15859c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import the libraries for regression algorithms:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b87c1b9f-5a15-4ada-b881-d8df6ed059ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to split the dataset into features and target:\n",
    "X = scaled_data.iloc[:, :-1]\n",
    "y = scaled_data['Target']\n",
    "\n",
    "# to split into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bf20eea-790a-4452-b17b-3f527ddc1fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\suvid\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\suvid\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\suvid\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\suvid\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\suvid\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb443a3a-1630-4a92-9488-20d288b4e5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE: 0.7455813830127763\n",
      "Linear Regression R2 Score: 0.575787706032451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suvid\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression:\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions:\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluation:\n",
    "lr_rmse = mean_squared_error(y_test, lr_predictions, squared=False)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "\n",
    "print(\"Linear Regression RMSE:\", lr_rmse)\n",
    "print(\"Linear Regression R2 Score:\", lr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6194181-e700-4186-b71f-118f604170c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: 0.7030445773467542\n",
      "Decision Tree R2 Score: 0.6228111330554302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suvid\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regressor:\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions:\n",
    "dt_predictions = dt_model.predict(X_test)\n",
    "\n",
    "# Evaluation:\n",
    "dt_rmse = mean_squared_error(y_test, dt_predictions, squared=False)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)\n",
    "\n",
    "print(\"Decision Tree RMSE:\", dt_rmse)\n",
    "print(\"Decision Tree R2 Score:\", dt_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "521a0eff-0895-456a-a3f5-03aa6e594d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 0.5054678690929896\n",
      "Random Forest R2 Score: 0.805024407701793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suvid\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor:\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions:\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation:\n",
    "rf_rmse = mean_squared_error(y_test, rf_predictions, squared=False)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Random Forest RMSE:\", rf_rmse)\n",
    "print(\"Random Forest R2 Score:\", rf_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c21aff06-a94d-4936-bf98-5ca2a9b9b38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting RMSE: 0.5422167577867202\n",
      "Gradient Boosting R2 Score: 0.7756433164710084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suvid\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor:\n",
    "gb_model = GradientBoostingRegressor(random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions:\n",
    "gb_predictions = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluation:\n",
    "gb_rmse = mean_squared_error(y_test, gb_predictions, squared=False)\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "\n",
    "print(\"Gradient Boosting RMSE:\", gb_rmse)\n",
    "print(\"Gradient Boosting R2 Score:\", gb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f8293f7-e490-4450-8d99-5499aef30d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR RMSE: 0.595985286730253\n",
      "SVR R2 Score: 0.7289407597956462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suvid\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Regressor:\n",
    "svr_model = SVR(kernel='rbf')\n",
    "svr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions:\n",
    "svr_predictions = svr_model.predict(X_test)\n",
    "\n",
    "# Evaluation:\n",
    "svr_rmse = mean_squared_error(y_test, svr_predictions, squared=False)\n",
    "svr_r2 = r2_score(y_test, svr_predictions)\n",
    "\n",
    "print(\"SVR RMSE:\", svr_rmse)\n",
    "print(\"SVR R2 Score:\", svr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7d6f82e3-5135-457c-9e5e-59d41e7ee892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model      RMSE  R2 Score\n",
      "0  Linear Regression  0.745581  0.575788\n",
      "1      Decision Tree  0.703045  0.622811\n",
      "2      Random Forest  0.505468  0.805024\n",
      "3  Gradient Boosting  0.542217  0.775643\n",
      "4                SVR  0.595985  0.728941\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"Model\": [\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\", \"SVR\"],\n",
    "    \"RMSE\": [lr_rmse, dt_rmse, rf_rmse, gb_rmse, svr_rmse],\n",
    "    \"R2 Score\": [lr_r2, dt_r2, rf_r2, gb_r2, svr_r2]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310aa527-7950-4baf-bc02-d6c7607b8efe",
   "metadata": {},
   "source": [
    "**1. Linear Regression:**\r\n",
    "Linear Regression assumes a linear relationship between the input features (independent variables) and the target (dependent variable). The model minimizes the sum of squared residuals to find the best-fit line.\r\n",
    "\r\n",
    "**Why it is suitable:**\r\n",
    "\r\n",
    "*   **Interpretability:** Linear regression provides clear insights into feature importance.\r\n",
    "*   **Low Complexity:** It works well with datasets where features have a linear relationship with the target.\r\n",
    "*   **Limitations:** It may underperform if relationships are non-linear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c9735d-b343-46b6-bf5c-47fd793f3a4b",
   "metadata": {},
   "source": [
    "**2. Decision Tree Regressor:**\r\n",
    "Decision Tree Regressor splits the dataset into smaller subsets based on feature thresholds. It creates a tree structure where leaf nodes represent the average value of the target for that subset.\r\n",
    "\r\n",
    "**Why it is suitable:**\r\n",
    "\r\n",
    "*   **Non-linearity:** Handles non-linear relationships better than Linear Regression.\r\n",
    "*   **Feature Importance:** Automatically identifies the most important features.\r\n",
    "*   **Limitations:** Can overfit, especially if not pruned or regularized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1610812-292a-433d-8e35-b9a4b1932879",
   "metadata": {},
   "source": [
    "**3. Random Forest Regressor:**\r\n",
    "Random Forest is an ensemble method that combines multiple Decision Trees, each trained on a random subset of the data (both rows and columns). The final prediction is the average of predictions from all trees.\r\n",
    "\r\n",
    "**Why it is suitable:**\r\n",
    "\r\n",
    "*   **Robustness:** Reduces overfitting seen in Decision Trees.\r\n",
    "*   **Accuracy:** Performs well on datasets with complex relationships and interactions.\r\n",
    "*   **Feature Selection:** Identifies key features automatically.\r\n",
    "*   **Limitations:** Computationally expensive for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454390e4-e682-4830-af16-93db08a15b81",
   "metadata": {},
   "source": [
    "**4. Gradient Boosting Regressor:**\r\n",
    "Gradient Boosting builds models sequentially, where each new model focuses on correcting the errors of the previous ones. It minimizes a loss function (e.g., MSE) using gradient descent.\r\n",
    "\r\n",
    "**Why it is suitable:**\r\n",
    "\r\n",
    "*   **High Accuracy:** Works well for complex datasets with non-linear relationships.\r\n",
    "*   **Customizable:** Can optimize for specific loss functions.\r\n",
    "*   **Limitations:** Sensitive to hyperparameters and may overfit if not tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed91f12-e098-4593-a68e-db6de4bf8fc1",
   "metadata": {},
   "source": [
    "**5. Support Vector Regressor (SVR):**\r\n",
    "SVR uses a margin-based approach to predict the target values, aiming to fit the data within a \"tube\" around the true values. It uses kernels (e.g., linear, polynomial, RBF) to capture non-linear relationships.\r\n",
    "\r\n",
    "**Why it is suitable:**\r\n",
    "\r\n",
    "*   **Non-linear Relationships:** Works well with kernels like RBF to handle complex relationships.\r\n",
    "*   **Small Datasets:** Effective on smaller datasets where computational cost is manageable.\r\n",
    "*   **Limitations:** Computationally expensive for large datasets; sensitive to hyperparameters like C and epsilon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b30ae-394e-4896-ae65-825a3891a465",
   "metadata": {},
   "source": [
    "# **3. Model Evaluation and Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19a2c83e-5d77-4385-bafa-344a178738ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd  # to create a comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d8c6eee6-d0af-45de-9111-a2414f7fa8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Metrics:\n",
      "MSE: 0.5558915986952442\n",
      "MAE: 0.5332001304956565\n",
      "R²: 0.575787706032451\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Evaluation:\n",
    "lr_mse = mean_squared_error(y_test, lr_predictions)\n",
    "lr_mae = mean_absolute_error(y_test, lr_predictions)\n",
    "lr_r2 = r2_score(y_test, lr_predictions)\n",
    "\n",
    "print(\"Linear Regression Metrics:\")\n",
    "print(\"MSE:\", lr_mse)\n",
    "print(\"MAE:\", lr_mae)\n",
    "print(\"R²:\", lr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08896202-3e0e-4ad6-b3f3-6393e8509f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor Metrics:\n",
      "MSE: 0.4942716777366763\n",
      "MAE: 0.4537843265503876\n",
      "R²: 0.6228111330554302\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Regressor Evaluation:\n",
    "dt_mse = mean_squared_error(y_test, dt_predictions)\n",
    "dt_mae = mean_absolute_error(y_test, dt_predictions)\n",
    "dt_r2 = r2_score(y_test, dt_predictions)\n",
    "\n",
    "print(\"Decision Tree Regressor Metrics:\")\n",
    "print(\"MSE:\", dt_mse)\n",
    "print(\"MAE:\", dt_mae)\n",
    "print(\"R²:\", dt_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b92ffef6-b3f3-4ff7-a1e0-fe59e9b098d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Metrics:\n",
      "MSE: 0.25549776668540763\n",
      "MAE: 0.32761306601259704\n",
      "R²: 0.805024407701793\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regressor Evaluation:\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "rf_r2 = r2_score(y_test, rf_predictions)\n",
    "\n",
    "print(\"Random Forest Regressor Metrics:\")\n",
    "print(\"MSE:\", rf_mse)\n",
    "print(\"MAE:\", rf_mae)\n",
    "print(\"R²:\", rf_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c39db4c-6694-44ee-b514-17d3ff02ec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Metrics:\n",
      "MSE: 0.29399901242474274\n",
      "MAE: 0.37165044848436773\n",
      "R²: 0.7756433164710084\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regressor Evaluation:\n",
    "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
    "gb_mae = mean_absolute_error(y_test, gb_predictions)\n",
    "gb_r2 = r2_score(y_test, gb_predictions)\n",
    "\n",
    "print(\"Gradient Boosting Regressor Metrics:\")\n",
    "print(\"MSE:\", gb_mse)\n",
    "print(\"MAE:\", gb_mae)\n",
    "print(\"R²:\", gb_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "32d94d32-ec47-415c-8cbb-e476e522d3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regressor Metrics:\n",
      "MSE: 0.3551984619989419\n",
      "MAE: 0.3977630963437859\n",
      "R²: 0.7289407597956462\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Regressor Evaluation:\n",
    "svr_mse = mean_squared_error(y_test, svr_predictions)\n",
    "svr_mae = mean_absolute_error(y_test, svr_predictions)\n",
    "svr_r2 = r2_score(y_test, svr_predictions)\n",
    "\n",
    "print(\"Support Vector Regressor Metrics:\")\n",
    "print(\"MSE:\", svr_mse)\n",
    "print(\"MAE:\", svr_mae)\n",
    "print(\"R²:\", svr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ee7a770-90e0-401c-94e0-7d9beea1daa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model       MSE       MAE        R²\n",
      "0  Linear Regression  0.555892  0.533200  0.575788\n",
      "1      Decision Tree  0.494272  0.453784  0.622811\n",
      "2      Random Forest  0.255498  0.327613  0.805024\n",
      "3  Gradient Boosting  0.293999  0.371650  0.775643\n",
      "4                SVR  0.355198  0.397763  0.728941\n"
     ]
    }
   ],
   "source": [
    "# to create a DataFrame to compare results:\n",
    "results = {\n",
    "    \"Model\": [\"Linear Regression\", \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\", \"SVR\"],\n",
    "    \"MSE\": [lr_mse, dt_mse, rf_mse, gb_mse, svr_mse],\n",
    "    \"MAE\": [lr_mae, dt_mae, rf_mae, gb_mae, svr_mae],\n",
    "    \"R²\": [lr_r2, dt_r2, rf_r2, gb_r2, svr_r2],\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(results)\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981b0d1-eec4-4d98-bd57-01c69eeff3ee",
   "metadata": {},
   "source": [
    "## **Analysis:**\n",
    "**Best-Performing Algorithm:**\n",
    "\n",
    "**Model:** Random Forest Regressor \n",
    "\n",
    "**Justification:**\n",
    "*   It has the lowest MSE (0.255608), indicating the smallest average squared error.\n",
    "*   It also has the lowest MAE (0.327683), indicating the smallest average absolute error.\n",
    "*   It achieved the highest R² score (0.804885), meaning it explains approximately 80.49% of the variance in the target variable.\n",
    "*   Random Forest works well because it combines the predictions of multiple decision trees to improve accuracy and reduce overfitting, making it a robust choice for this dataset.\n",
    "\n",
    "**Worst-Performing Algorithm:**\n",
    "\n",
    "**Model:** Linear Regression\n",
    "\n",
    "**Reasoning:**\n",
    "\n",
    "*   It has the highest MSE (0.555892) and highest MAE (0.533200), indicating the largest errors in predictions.\n",
    "*   It has the lowest R² score (0.575788), meaning it explains only 57.58% of the variance in the target variable.\n",
    "*   Linear Regression assumes a linear relationship between features and the target variable, which may not capture the complexity and nonlinearity in the fetch_california_housing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85399943-112c-46a0-9abe-8b22eefaf4c8",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "**Best Algorithm: Random Forest Regressor** (justification: superior metrics, robust to overfitting, handles nonlinearity well).\n",
    "\n",
    "**Worst Algorithm: Linear Regression** (reasoning: poor performance due to its linearity assumption, which is not well-suited for complex datasets)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
